{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage import color\nimport json\n# test\n# testing\n# from google.colab import files","metadata":{"id":"L5QrUWbbdpMs","execution":{"iopub.status.busy":"2024-04-15T15:19:07.983183Z","iopub.execute_input":"2024-04-15T15:19:07.983472Z","iopub.status.idle":"2024-04-15T15:19:30.797494Z","shell.execute_reply.started":"2024-04-15T15:19:07.983447Z","shell.execute_reply":"2024-04-15T15:19:30.796458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TensorFlow version: \", tf.__version__)\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:19:30.799020Z","iopub.execute_input":"2024-04-15T15:19:30.799518Z","iopub.status.idle":"2024-04-15T15:19:31.225862Z","shell.execute_reply.started":"2024-04-15T15:19:30.799492Z","shell.execute_reply":"2024-04-15T15:19:31.224719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nif tf.test.gpu_device_name():\n    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\nelse:\n    print(\"Please install GPU version of TF\")","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:19:31.227159Z","iopub.execute_input":"2024-04-15T15:19:31.227532Z","iopub.status.idle":"2024-04-15T15:19:31.487837Z","shell.execute_reply.started":"2024-04-15T15:19:31.227488Z","shell.execute_reply":"2024-04-15T15:19:31.486805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_data(dataset, train_size, valid_size, test_size):\n  total_length = len(dataset)\n  train_length = int(np.floor(total_length * train_size))\n  valid_length = int(np.floor(total_length * valid_size))\n\n  train_data = dataset.take(train_length)\n  remaining = dataset.skip(train_length)\n  valid_data = remaining.take(valid_length)\n  test_data = remaining.skip(valid_length)\n\n#   train_x = x[:train_breakpoint]\n#   train_y = y[:train_breakpoint]\n#   valid_x = x[train_breakpoint:valid_breakpoint]\n#   valid_y = y[train_breakpoint:valid_breakpoint]\n#   test_x = x[valid_breakpoint:]\n#   test_y = y[valid_breakpoint:]\n\n  return train_data, valid_data, test_data","metadata":{"id":"3-OifnOBtjFP","execution":{"iopub.status.busy":"2024-04-15T15:19:31.490177Z","iopub.execute_input":"2024-04-15T15:19:31.491076Z","iopub.status.idle":"2024-04-15T15:19:31.500899Z","shell.execute_reply.started":"2024-04-15T15:19:31.491038Z","shell.execute_reply":"2024-04-15T15:19:31.500038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_lab(image):\n    image = np.array(image)\n    # OpenCV's 'cvtColor' function expects the input image to be in the BGR color space,\n    # so we need to convert from RGB to BGR first\n    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n\n    # Now we can convert from BGR to CIE L*a*b*\n    image_lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2Lab)\n\n    return image_lab","metadata":{"id":"UwAa7jMJyRWe","execution":{"iopub.status.busy":"2024-04-15T15:19:31.501884Z","iopub.execute_input":"2024-04-15T15:19:31.502167Z","iopub.status.idle":"2024-04-15T15:19:31.511086Z","shell.execute_reply.started":"2024-04-15T15:19:31.502144Z","shell.execute_reply":"2024-04-15T15:19:31.510359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(img, label, use_lab_color_space=True):\n  img = tf.image.resize(img, (128, 128))\n  img /= 255.\n\n  if (use_lab_color_space):\n    img = tf.py_function(func=color.rgb2lab, inp=[img], Tout=tf.float32)\n    img = (img + [0, 128, 128]) / [100, 255, 255]\n    \n#     img = color.rgb2lab(img, channel_axis=2)\n#     img[:, :, 0] = img[:, :, 0] / 100\n#     img[:, :, 1:] = (img[:, :, 1:] + 128) / 255\n\n  img.set_shape((128, 128, 3))\n  label = tf.one_hot(label, depth=38)\n\n  return img, label","metadata":{"id":"iVmY-bBfu02N","execution":{"iopub.status.busy":"2024-04-15T15:19:31.512282Z","iopub.execute_input":"2024-04-15T15:19:31.512854Z","iopub.status.idle":"2024-04-15T15:19:31.522239Z","shell.execute_reply.started":"2024-04-15T15:19:31.512823Z","shell.execute_reply":"2024-04-15T15:19:31.521494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the validation and training curves separately\ndef plot_loss_curves(history):\n    \"\"\"\n    Returns separate loss curves for training and validation metrics\n    \"\"\"\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n\n    epochs = range(len(history.history['loss'])) # How many epochs\n\n\n    # Plot loss\n    plt.plot(epochs, loss, label=\"training_loss\")\n    plt.plot(epochs, val_loss, label=\"val_loss\")\n    plt.title(\"loss\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot accuracy\n    plt.figure()\n    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n    plt.title(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:19:31.523359Z","iopub.execute_input":"2024-04-15T15:19:31.523616Z","iopub.status.idle":"2024-04-15T15:19:31.540423Z","shell.execute_reply.started":"2024-04-15T15:19:31.523595Z","shell.execute_reply":"2024-04-15T15:19:31.539558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# PLANT VILLAGE","metadata":{"id":"TMz-YGCRxsqb"}},{"cell_type":"code","source":"# Construct a tf.data.Dataset\ndataset, ds_info = tfds.load('plant_village',\n              split=\"train\",\n              with_info=True,\n              shuffle_files=True,\n              as_supervised=True)","metadata":{"id":"HKbIPLaWoepQ","execution":{"iopub.status.busy":"2024-04-15T15:19:31.541548Z","iopub.execute_input":"2024-04-15T15:19:31.541824Z","iopub.status.idle":"2024-04-15T15:22:05.356043Z","shell.execute_reply.started":"2024-04-15T15:19:31.541801Z","shell.execute_reply":"2024-04-15T15:22:05.354969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.shuffle(500)","metadata":{"id":"vZS07EWwU-6G","outputId":"013fb362-795a-4a78-ef0b-e8fab019776f","execution":{"iopub.status.busy":"2024-04-15T15:22:27.892285Z","iopub.execute_input":"2024-04-15T15:22:27.892668Z","iopub.status.idle":"2024-04-15T15:22:27.901413Z","shell.execute_reply.started":"2024-04-15T15:22:27.892638Z","shell.execute_reply":"2024-04-15T15:22:27.900512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(dataset))","metadata":{"id":"r7rYh7mhuKUf","outputId":"a379cf96-98d3-4360-f47b-1dc86c9f2604","execution":{"iopub.status.busy":"2024-04-15T15:22:28.526900Z","iopub.execute_input":"2024-04-15T15:22:28.527299Z","iopub.status.idle":"2024-04-15T15:22:28.533079Z","shell.execute_reply.started":"2024-04-15T15:22:28.527269Z","shell.execute_reply":"2024-04-15T15:22:28.532144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfds.show_examples(dataset, ds_info)","metadata":{"id":"PSNuUkE_rsY-","outputId":"fbf39e03-dbdc-4126-d364-04e3b810493b","execution":{"iopub.status.busy":"2024-04-15T15:22:29.253758Z","iopub.execute_input":"2024-04-15T15:22:29.254136Z","iopub.status.idle":"2024-04-15T15:22:30.583438Z","shell.execute_reply.started":"2024-04-15T15:22:29.254108Z","shell.execute_reply":"2024-04-15T15:22:30.582505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(preprocess_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T15:22:30.585108Z","iopub.execute_input":"2024-04-15T15:22:30.585777Z","iopub.status.idle":"2024-04-15T15:22:30.728722Z","shell.execute_reply.started":"2024-04-15T15:22:30.585747Z","shell.execute_reply":"2024-04-15T15:22:30.727691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iterator = iter(dataset)\ntest= next(iterator)\n\n# Search for data with early blight condition\nif (np.argmax(test[1]) != 19):\n    test = next(iterator)\n    \ntest = np.copy(test[0])\n\nl_channel = test[:, :, 0]\n\nab_channel = test[:, :, 1:]\nones_array = np.zeros((ab_channel.shape[0], ab_channel.shape[1], 1))\nab_channel = np.concatenate((ones_array, ab_channel), axis=2)\nab_channel = (ab_channel * [100, 255, 255] - [0, 128, 128]) * [0, 255, 255]\nprint(ab_channel[0][0])\nab_channel = color.lab2rgb(ab_channel)\n\nprint(ab_channel[0][0])\n\n# Plot the image\nfig, axs = plt.subplots(1, 2, figsize=(10, 10))\nfig.subplots_adjust(hspace=0.5)\naxs[0].imshow(l_channel, cmap='gray')\naxs[0].set_title('L Channel')\naxs[1].imshow(ab_channel)\naxs[1].set_title('AB Channel')\n\n# Show the plot\nplt.show()","metadata":{"id":"eBgrZ9FBG2I4","outputId":"0c5ed2b1-c531-48d7-9f24-fe3b70b92a02","execution":{"iopub.status.busy":"2024-04-15T15:40:53.453089Z","iopub.execute_input":"2024-04-15T15:40:53.454235Z","iopub.status.idle":"2024-04-15T15:40:53.966234Z","shell.execute_reply.started":"2024-04-15T15:40:53.454187Z","shell.execute_reply":"2024-04-15T15:40:53.965399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, valid_data, test_data = split_data(\n    dataset=dataset,\n    train_size=0.6,\n    valid_size=0.2,\n    test_size=0.2\n  )","metadata":{"id":"LrHXj4KXvG1q","execution":{"iopub.status.busy":"2024-04-15T15:27:36.806242Z","iopub.execute_input":"2024-04-15T15:27:36.806643Z","iopub.status.idle":"2024-04-15T15:27:36.818033Z","shell.execute_reply.started":"2024-04-15T15:27:36.806611Z","shell.execute_reply":"2024-04-15T15:27:36.817047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_data), len(valid_data), len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T01:28:09.486719Z","iopub.execute_input":"2024-04-15T01:28:09.487090Z","iopub.status.idle":"2024-04-15T01:28:09.493018Z","shell.execute_reply.started":"2024-04-15T01:28:09.487058Z","shell.execute_reply":"2024-04-15T01:28:09.492041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.batch(32)\nvalid_data = valid_data.batch(32)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T01:28:44.297215Z","iopub.execute_input":"2024-04-15T01:28:44.297570Z","iopub.status.idle":"2024-04-15T01:28:44.305397Z","shell.execute_reply.started":"2024-04-15T01:28:44.297545Z","shell.execute_reply":"2024-04-15T01:28:44.304466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TWO BRANCH INCEPTION V3","metadata":{"id":"rw7flHvmgbsk"}},{"cell_type":"code","source":"module_filters = [\n    [64, 48, 64, 64, 96, 96, 32],\n    [64, 48, 64, 64, 96, 96, 64],\n    [64, 48, 64, 64, 96, 96, 64],\n    [192, 128, 128, 192, 128, 128, 128, 128, 192, 192],\n    [192, 160, 160, 192, 160, 160, 160, 160, 192, 192],\n    [192, 160, 160, 192, 160, 160, 160, 160, 192, 192],\n    [192, 192, 192, 192, 192, 192, 192, 192, 192, 192],\n    [192, 192, 192, 192, 192, 192, 192, 192, 192, 192],\n    [320, 384, 384, 384, 448, 384, 384, 384, 192],\n    [320, 384, 384, 384, 448, 384, 384, 384, 192],\n]","metadata":{"id":"nKwcfSi3tout","execution":{"iopub.status.busy":"2024-04-15T01:28:09.627665Z","iopub.execute_input":"2024-04-15T01:28:09.627962Z","iopub.status.idle":"2024-04-15T01:28:09.636204Z","shell.execute_reply.started":"2024-04-15T01:28:09.627938Z","shell.execute_reply":"2024-04-15T01:28:09.635345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CopyChannels(tf.keras.layers.Layer):\n    \"\"\"\n    This layer copies channels from channel_start the number of channels given in channel_count.\n    \"\"\"\n    def __init__(self,\n                 channel_start=0,\n                 channel_count=1,\n                 **kwargs):\n        self.channel_start=channel_start\n        self.channel_count=channel_count\n        super(CopyChannels, self).__init__(**kwargs)\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[1], self.channel_count)\n\n    def call(self, x):\n        return x[:, :, self.channel_start:(self.channel_start+self.channel_count)]\n\n    def get_config(self):\n        config = {\n            'channel_start': self.channel_start,\n            'channel_count': self.channel_count\n        }\n        base_config = super(CopyChannels, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","metadata":{"id":"pGNV1LfUKu19","execution":{"iopub.status.busy":"2024-04-15T01:28:09.843016Z","iopub.execute_input":"2024-04-15T01:28:09.843332Z","iopub.status.idle":"2024-04-15T01:28:09.851675Z","shell.execute_reply.started":"2024-04-15T01:28:09.843308Z","shell.execute_reply":"2024-04-15T01:28:09.850414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2d_bn(x, filters, kernel_size, padding='same', strides=1, name=None):\n    x = tf.keras.layers.Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=False)(x)\n    x = tf.keras.layers.BatchNormalization(scale=False)(x)\n    return tf.keras.layers.Activation('relu')(x)","metadata":{"id":"3aURrrdGnJo4","execution":{"iopub.status.busy":"2024-04-15T01:28:10.060736Z","iopub.execute_input":"2024-04-15T01:28:10.061130Z","iopub.status.idle":"2024-04-15T01:28:10.067010Z","shell.execute_reply.started":"2024-04-15T01:28:10.061102Z","shell.execute_reply":"2024-04-15T01:28:10.065962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inception_module_1(x, filters):\n  t1 = conv2d_bn(x, filters[0], 1)\n\n  t2 = conv2d_bn(x, filters[1], 1)\n  t2 = conv2d_bn(t2, filters[2], 3)\n\n  t3 = conv2d_bn(x, filters[3], 1)\n  t3 = conv2d_bn(t3, filters[4], 3)\n  t3 = conv2d_bn(t3, filters[5], 3)\n\n  t4 = tf.keras.layers.MaxPooling2D(3, strides=1, padding='same')(x)\n  t4 = conv2d_bn(t4, filters[6], 1)\n\n  return tf.keras.layers.concatenate([t1, t2, t3, t4], axis=3)","metadata":{"id":"WgwInXkfoL9C","execution":{"iopub.status.busy":"2024-04-15T01:28:10.398002Z","iopub.execute_input":"2024-04-15T01:28:10.398308Z","iopub.status.idle":"2024-04-15T01:28:10.404913Z","shell.execute_reply.started":"2024-04-15T01:28:10.398285Z","shell.execute_reply":"2024-04-15T01:28:10.404014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inception_module_2(x, filters):\n  t1 = conv2d_bn(x, filters[0], 1)\n\n  t2 = conv2d_bn(x, filters[1], 1)\n  t2 = conv2d_bn(t2, filters[2], (1,7))\n  t2 = conv2d_bn(t2, filters[3], (7,1))\n\n  t3 = conv2d_bn(x, filters[4], 1)\n  t3 = conv2d_bn(t3, filters[5], (1,7))\n  t3 = conv2d_bn(t3, filters[6], (7,1))\n  t3 = conv2d_bn(t3, filters[7], (1,7))\n  t3 = conv2d_bn(t3, filters[8], (7,1))\n\n  t4 = tf.keras.layers.MaxPooling2D(3, strides=1, padding='same')(x)\n  t4 = conv2d_bn(t4, filters[9], 1)\n\n  return tf.keras.layers.concatenate([t1, t2, t3, t4], axis=3)","metadata":{"id":"KGPcLtFsolAe","execution":{"iopub.status.busy":"2024-04-15T01:28:10.809858Z","iopub.execute_input":"2024-04-15T01:28:10.810169Z","iopub.status.idle":"2024-04-15T01:28:10.818106Z","shell.execute_reply.started":"2024-04-15T01:28:10.810146Z","shell.execute_reply":"2024-04-15T01:28:10.817167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inception_module_3(x, filters):\n  t1 = conv2d_bn(x, filters[0], 1)\n\n  t2 = conv2d_bn(x, filters[1], 1)\n  t2_1 = conv2d_bn(t2, filters[2], (1,3))\n  t2_2 = conv2d_bn(t2, filters[3], (3,1))\n  t2 = tf.keras.layers.concatenate([t2_1, t2_2], axis=3)\n\n  t3 = conv2d_bn(x, filters[4], 1)\n  t3 = conv2d_bn(t3, filters[5], 1)\n  t3_1 = conv2d_bn(t3, filters[6], (1,3))\n  t3_2 = conv2d_bn(t3, filters[7], (3,1))\n  t3 = tf.keras.layers.concatenate([t3_1, t3_2], axis=3)\n\n  t4 = tf.keras.layers.MaxPooling2D(3, strides=1, padding='same')(x)\n  t4 = conv2d_bn(t4, filters[8], 1)\n\n  return tf.keras.layers.concatenate([t1, t2, t3, t4], axis=3)","metadata":{"id":"UL28ZsICqRw7","execution":{"iopub.status.busy":"2024-04-15T01:28:11.056088Z","iopub.execute_input":"2024-04-15T01:28:11.056388Z","iopub.status.idle":"2024-04-15T01:28:11.064368Z","shell.execute_reply.started":"2024-04-15T01:28:11.056365Z","shell.execute_reply":"2024-04-15T01:28:11.063374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def two_path_inception_v3(\n                include_top=True,\n                include_first_block=True,\n                weights=None, #'two_paths_plant_leafs'\n                input_shape=(128,128,3),\n                pooling=None,\n                classes=38,\n                two_paths_partial_first_block=0,\n                two_paths_first_block=False,\n                l_ratio=0.2,\n                ab_ratio=0.8,\n                max_mix_idx=10,\n                model_name='two_path_inception_v3',\n                **kwargs):\n\n    img_input = tf.keras.layers.Input(shape=input_shape)\n\n    if include_first_block:\n        if two_paths_first_block:\n            if (l_ratio>0):\n                l_branch = CopyChannels(0,1)(img_input)\n                l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), (3, 3), strides=(2, 2), padding='valid')\n                l_branch = conv2d_bn(l_branch, int(round(32*l_ratio)), (3, 3), padding='valid')\n                l_branch = conv2d_bn(l_branch, int(round(64*l_ratio)), (3, 3))\n                l_branch = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(l_branch)\n\n            if (ab_ratio>0):\n                ab_branch = CopyChannels(1,2)(img_input)\n                ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), (3, 3), strides=(2, 2), padding='valid')\n                ab_branch = conv2d_bn(ab_branch, int(round(32*ab_ratio)), (3, 3), padding='valid')\n                ab_branch = conv2d_bn(ab_branch, int(round(64*ab_ratio)), (3, 3))\n                ab_branch = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(ab_branch)\n\n            if (l_ratio>0):\n                if (ab_ratio>0):\n                    x = tf.keras.layers.Concatenate(axis=3, name='concat_first_block')([l_branch, ab_branch])\n                else:\n                    x = l_branch\n            else:\n                x = ab_branch\n        else:\n            single_branch = conv2d_bn(img_input, 32, (3, 3), strides=(2, 2), padding='valid')\n            single_branch = conv2d_bn(single_branch, 32, (3, 3), padding='valid')\n            single_branch = conv2d_bn(single_branch, 64, (3, 3))\n            single_branch = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(single_branch)\n            # print('single path first block')\n            x = single_branch\n\n    if max_mix_idx >= 0:\n        for i in range(max_mix_idx):\n          if i < 3:\n            x = inception_module_1(x, module_filters[i])\n          elif i < 8:\n            x = inception_module_2(x, module_filters[i])\n          else:\n            x = inception_module_3(x, module_filters[i])\n\n    if include_top:\n        # Classification block\n        x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n        x = tf.keras.layers.Dense(classes, activation='softmax', name='predictions')(x)\n    else:\n        if pooling == 'avg':\n            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n\n    inputs = img_input\n    # Create model.\n    model = tf.keras.models.Model(inputs, x, name=model_name)\n    return model","metadata":{"id":"zyOBZG-RgvCQ","execution":{"iopub.status.busy":"2024-04-15T01:28:11.569274Z","iopub.execute_input":"2024-04-15T01:28:11.569868Z","iopub.status.idle":"2024-04-15T01:28:11.588826Z","shell.execute_reply.started":"2024-04-15T01:28:11.569840Z","shell.execute_reply":"2024-04-15T01:28:11.587708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EXPERIMENTS","metadata":{}},{"cell_type":"code","source":"print(\"Train data shape:\", tf.data.experimental.cardinality(train_data).numpy())\nprint(\"Valid data shape:\", tf.data.experimental.cardinality(valid_data).numpy())","metadata":{"execution":{"iopub.status.busy":"2024-04-15T01:29:02.596680Z","iopub.execute_input":"2024-04-15T01:29:02.597593Z","iopub.status.idle":"2024-04-15T01:29:02.603719Z","shell.execute_reply.started":"2024-04-15T01:29:02.597563Z","shell.execute_reply":"2024-04-15T01:29:02.602725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect the shape of one element of train_data\nfor image, label in train_data.take(5):\n    print(\"Image shape:\", image.shape)\n    print(\"Label shape:\", label.shape)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-15T01:29:03.658906Z","iopub.execute_input":"2024-04-15T01:29:03.659508Z","iopub.status.idle":"2024-04-15T01:29:04.211648Z","shell.execute_reply.started":"2024-04-15T01:29:03.659476Z","shell.execute_reply":"2024-04-15T01:29:04.210704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n        loss='categorical_crossentropy',\n        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n        metrics=['accuracy'])","metadata":{"id":"WAIewJm43Dwe","execution":{"iopub.status.busy":"2024-04-14T12:11:40.208540Z","iopub.execute_input":"2024-04-14T12:11:40.208829Z","iopub.status.idle":"2024-04-14T12:11:40.218254Z","shell.execute_reply.started":"2024-04-14T12:11:40.208805Z","shell.execute_reply":"2024-04-14T12:11:40.217398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monitor='val_accuracy'\nepochs=10\n\nhistory = model.fit(\n    train_data,\n    verbose=1,\n    epochs=epochs,\n    validation_data=valid_data\n)","metadata":{"id":"QVLSZj_53pcl","outputId":"0d106bc7-7845-4fb1-a683-9ab67cab28c0","execution":{"iopub.status.busy":"2024-04-14T12:11:40.219289Z","iopub.execute_input":"2024-04-14T12:11:40.219550Z","iopub.status.idle":"2024-04-14T13:42:51.215836Z","shell.execute_reply.started":"2024-04-14T12:11:40.219528Z","shell.execute_reply":"2024-04-14T13:42:51.214954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_curves(history)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:43:18.869745Z","iopub.execute_input":"2024-04-14T13:43:18.870364Z","iopub.status.idle":"2024-04-14T13:43:19.497461Z","shell.execute_reply.started":"2024-04-14T13:43:18.870329Z","shell.execute_reply":"2024-04-14T13:43:19.496531Z"},"trusted":true},"execution_count":null,"outputs":[]}]}